{% set name = "xgboost" %}
{% set version = "1.7.6" %}

# note: r-xgboost is built from https://github.com/AnacondaRecipes/aggregateR/tree/R-4.3.1/r-xgboost-feedstock

package:
  name: {{ name|lower }}-split
  version: {{ version }}

source:
  url: https://github.com/dmlc/xgboost/releases/download/v1.7.6/xgboost.tar.gz
  sha256: 0a54300dd274b98b7f039acffa006bec4875dace041fd9288422306fe7c379ca
  patches:
    - 0001-conda-Unbundle-libxgboost.-dll-dylib-so.patch

build:
  skip: True  # [py<38]
  number: 0

requirements:
  build:
    - patch                  # [not win]
    - m2-patch               # [win]

outputs:
  - name: libxgboost
    script: install-libxgboost.sh  # [not win]
    script: install-libxgboost.bat  # [win]
    build:
      skip: True  # [py<38]
      missing_dso_whitelist:
        - $RPATH/ld64.so.1  # [s390x]
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - cmake
        - ninja
        - llvm-openmp  # [osx]
      host:
        - llvm-openmp  # [osx]
      run:
        - llvm-openmp  # [osx]
        - _openmp_mutex  # [linux]
    test:
      commands:
        - test -f ${PREFIX}/lib/libxgboost${SHLIB_EXT}       # [unix]
        - if not exist %LIBRARY_BIN%\\xgboost.dll exit 1     # [win]

  - name: _py-xgboost-mutex
    version: 2.0
    build:
      skip: True  # [py<38]
      string: cpu_0
      number: 0
    test:
      commands:
        - echo "Hello py boost!"

  - name: py-xgboost
    script: install-py-xgboost.sh  # [not win]
    script: install-py-xgboost.bat  # [win]
    build:
      skip: True  # [py<38]
    requirements:
      host:
        - python
        - setuptools
        - pip
        - wheel
      run:
        - {{ pin_subpackage('libxgboost', exact=True) }}
        - {{ pin_subpackage('_py-xgboost-mutex', exact=True) }}
        - python
        - numpy
        - scipy
        - scikit-learn
          # mkl variant pulls in intel-openmp which conflicts with llvm-openmp. i.e. force to use openblas variant of numpy, scipy, etc.
        - blas=*=openblas  # [osx and x86_64]
    test:
      requires:
        - pip
      script: test-py-xgboost.py        # [not s390x]
      imports:
        - xgboost
      commands:
        - pip check

  - name: py-xgboost-cpu
    build:
      skip: True  # [py<38]
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage('py-xgboost', exact=True) }}

  - name: xgboost
    build:
      skip: True  # [py<38]
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage('py-xgboost', exact=True) }}

about:
  home: https://github.com/dmlc/xgboost
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE
  summary: |
    Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library, for
    Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Flink
    and DataFlow
  description: |
    XGBoost is an optimized distributed gradient boosting library designed to be highly efficient,
    flexible and portable. It implements machine learning algorithms under the Gradient Boosting
    framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many
    data science problems in a fast and accurate way. The same code runs on major distributed
    environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.
  doc_url: https://xgboost.readthedocs.io/
  dev_url: https://github.com/dmlc/xgboost/

extra:
  feedstock-name: xgboost
  recipe-maintainers:
    - aldanor
    - fhoehle
    - jakirkham
    - ksangeek
    - xhochy
